{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3861c09-c339-4404-b42d-3b40c5c80444",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-24T21:37:29.369385Z",
     "iopub.status.busy": "2024-08-24T21:37:29.368714Z",
     "iopub.status.idle": "2024-08-24T21:37:29.381189Z",
     "shell.execute_reply": "2024-08-24T21:37:29.378839Z",
     "shell.execute_reply.started": "2024-08-24T21:37:29.369334Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nFrom Yanis Bouchilloux, the 24/08/2024\\n\\nThis file is a lightened version of the file \"train_model\"\\nIn this one, all cells can be executed (in the linear order).\\nYou can read the descriptions of the cells to know more about their roles.\\n\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "Yanis Bouchilloux                              24/08/2024\n",
    "\n",
    "This file is a lightened version of the file \"train_model\"\n",
    "In this one, all cells can be executed (in the linear order).\n",
    "You can read the descriptions of the cells to know more about their roles.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c53a9b2d-9e22-46e0-aab8-fadf07e86de4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-24T21:37:07.101639Z",
     "iopub.status.busy": "2024-08-24T21:37:07.101049Z",
     "iopub.status.idle": "2024-08-24T21:37:15.981779Z",
     "shell.execute_reply": "2024-08-24T21:37:15.979305Z",
     "shell.execute_reply.started": "2024-08-24T21:37:07.101591Z"
    }
   },
   "outputs": [],
   "source": [
    "#Import all the libraries needed in this Notebook\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments\n",
    "from datasets import Dataset\n",
    "from trl import SFTTrainer\n",
    "import torch\n",
    "import json\n",
    "\n",
    "MODEL_ID = \"microsoft/Phi-3-mini-4k-instruct\"\n",
    "NEW_MODEL_NAME = \"train-model-phi-3-mini-4k\"\n",
    "DATASET_NAME = \"macadeliccc/opus_samantha\"\n",
    "\n",
    "if torch.cuda.is_bf16_supported():\n",
    "    compute_dtype = torch.bfloat16\n",
    "else:\n",
    "    compute_dtype = torch.float16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f09ccbd-ddf5-4614-aa6c-4712caa8a26a",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-24T21:36:03.673365Z",
     "iopub.status.idle": "2024-08-24T21:36:03.674027Z",
     "shell.execute_reply": "2024-08-24T21:36:03.673879Z",
     "shell.execute_reply.started": "2024-08-24T21:36:03.673879Z"
    }
   },
   "outputs": [],
   "source": [
    "#Load the model and the tokenizer from phi-3\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(MODEL_ID)\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6903dd1-c433-4930-ad08-80771e83aba0",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-24T21:36:03.677183Z",
     "iopub.status.idle": "2024-08-24T21:36:03.677885Z",
     "shell.execute_reply": "2024-08-24T21:36:03.677532Z",
     "shell.execute_reply.started": "2024-08-24T21:36:03.677518Z"
    }
   },
   "outputs": [],
   "source": [
    "#Load the local datas and make it a Dataset object (need the file qa_dataset.json)\n",
    "\n",
    "with open('qa_dataset.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "def formatting_prompts_func(example):\n",
    "    return {\"Content\" : f\"Question: {example['question']}\\nAnswer: {example['answer']}\"}\n",
    "\n",
    "formatted_list = [formatting_prompts_func(item) for item in data]\n",
    "\n",
    "#print(formatted_dataset)\n",
    "\n",
    "dataset = Dataset.from_list(formatted_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4427fbae-3fa8-4919-869e-e4f56772c05f",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-24T21:36:03.680605Z",
     "iopub.status.idle": "2024-08-24T21:36:03.681634Z",
     "shell.execute_reply": "2024-08-24T21:36:03.681168Z",
     "shell.execute_reply.started": "2024-08-24T21:36:03.680887Z"
    }
   },
   "outputs": [],
   "source": [
    "#Tokenize the dataset and seperate it in the eval_dataset and the train_dataset\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"Content\"], truncation=True, padding=\"max_length\", max_length=128)\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize_function, batched=True, batch_size=4)\n",
    "\n",
    "shuffled_tokenized_dataset = tokenized_dataset.shuffle()\n",
    "\n",
    "eval_dataset = shuffled_tokenized_dataset.select(range(len(shuffled_tokenized_dataset) // 10))  # 10% pour l'Ã©valuation\n",
    "train_dataset = shuffled_tokenized_dataset.select(range(len(shuffled_tokenized_dataset) // 10, len(shuffled_tokenized_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de95d5c-7761-4957-840c-49f418113fc8",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-24T21:36:03.684444Z",
     "iopub.status.idle": "2024-08-24T21:36:03.685122Z",
     "shell.execute_reply": "2024-08-24T21:36:03.684840Z",
     "shell.execute_reply.started": "2024-08-24T21:36:03.684812Z"
    }
   },
   "outputs": [],
   "source": [
    "#Define the options for the fine-tuning\n",
    "\n",
    "args = TrainingArguments(\n",
    "eval_strategy=\"steps\",\n",
    "per_device_train_batch_size=7,\n",
    "gradient_accumulation_steps=4,\n",
    "gradient_checkpointing=True,\n",
    "learning_rate=1e-4,\n",
    "fp16 = not torch.cuda.is_bf16_supported(),\n",
    "bf16 = torch.cuda.is_bf16_supported(),\n",
    "max_steps=-1,\n",
    "num_train_epochs=3,\n",
    "save_strategy=\"epoch\",\n",
    "logging_steps=4,\n",
    "output_dir=NEW_MODEL_NAME,\n",
    "optim=\"paged_adamw_32bit\",\n",
    "lr_scheduler_type=\"linear\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7f00f4-f727-43ce-8486-b7ea3226d413",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-24T21:36:03.687485Z",
     "iopub.status.idle": "2024-08-24T21:36:03.688152Z",
     "shell.execute_reply": "2024-08-24T21:36:03.687867Z",
     "shell.execute_reply.started": "2024-08-24T21:36:03.687838Z"
    }
   },
   "outputs": [],
   "source": [
    "#Train of the model\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    train_dataset = train_dataset,\n",
    "    eval_dataset = eval_dataset,\n",
    "    args = args\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2141f54b-7c44-47c9-9d35-de54291a6e5b",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-24T21:36:03.689651Z",
     "iopub.status.idle": "2024-08-24T21:36:03.690255Z",
     "shell.execute_reply": "2024-08-24T21:36:03.689986Z",
     "shell.execute_reply.started": "2024-08-24T21:36:03.689958Z"
    }
   },
   "outputs": [],
   "source": [
    "#Generate local model\n",
    "\n",
    "model_checkpoint = \"./\"+NEW_MODEL_NAME+\"/checkpoint-48\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint,trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_checkpoint,\n",
    "                                             trust_remote_code=True,\n",
    "                                             torch_dtype=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd010d1e-1f8e-4ebf-8fe4-f48fb35180bc",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-08-24T21:36:03.692300Z",
     "iopub.status.idle": "2024-08-24T21:36:03.693089Z",
     "shell.execute_reply": "2024-08-24T21:36:03.692810Z",
     "shell.execute_reply.started": "2024-08-24T21:36:03.692781Z"
    }
   },
   "outputs": [],
   "source": [
    "#Test of the model\n",
    "\n",
    "prompt = \"What is SDGs?\"\n",
    "\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "outputs = model.generate(**inputs, \n",
    "    max_length=100, \n",
    "    min_length=50, \n",
    "    repetition_penalty=2.0\n",
    ")\n",
    "response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
